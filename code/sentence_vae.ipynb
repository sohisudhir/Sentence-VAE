{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NewHopeVAE.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "muibpWFmDKC4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.utils.rnn as rnn_utils\n",
        "import torch.distributions as distb\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "from datetime import datetime\n",
        "import argparse\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from pprint import pprint\n",
        "from torch.utils.data import Dataset\n",
        "from collections import Counter\n",
        "from torch.distributions.normal import Normal\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87bj8h8aWavL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSxEIP4K6WE1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pprint import pprint\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from collections import Counter\n",
        "\n",
        "class BaseTreeData(Dataset):\n",
        "    def __init__(self, train_data_path=\"02-21.10way.clean\", rare_threshold=1):\n",
        "        self.rare_threshold = rare_threshold\n",
        "        self.base_data = self.remove_tags(open(train_data_path, \"r\").read())\n",
        "        self.SOS = \"|new\"\n",
        "        self.EOS = \".\"\n",
        "        self.pad = \"<_>\"\n",
        "        self.rare = \"RARE\"\n",
        "        self.base_data.extend([self.SOS for i in range(self.rare_threshold + 1)])\n",
        "        self.base_data.extend([self.pad for i in range(self.rare_threshold + 1)])\n",
        "        self.base_data.extend([self.rare for i in range(self.rare_threshold + 1)])\n",
        "\n",
        "        self.vocab = list(set(self.base_data))        \n",
        "        self.define_mappings()\n",
        "\n",
        "        # self.sentences = [sentence for sentence in self.read_sentence(self.base_data)]\n",
        "        self.max_sentence_len = self.largest_sentence()\n",
        "\n",
        "    def define_mappings(self):\n",
        "        self.word_counter = Counter(self.base_data)\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        idx = 0\n",
        "        for w in self.vocab:\n",
        "            if self.word_counter[w] > self.rare_threshold:\n",
        "                self.word2idx[w] = idx\n",
        "                self.idx2word[idx] = w\n",
        "                idx+=1\n",
        "        self.vocab_size = len(self.word2idx)\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        # sentence = self.sentences[idx]\n",
        "        # inputs =  [self.word2idx[w] if self.word_counter[w] > self.rare_threshold else self.word2idx[self.rare] for w in sentence]\n",
        "        # targets = [self.word2idx[w] if self.word_counter[w] > self.rare_threshold else self.word2idx[self.rare] for w in sentence[1:]]\n",
        "        # # add padding\n",
        "        # inputs.extend([self.word2idx[self.pad] for i in range(self.max_sentence_len - len(inputs))])\n",
        "        # targets.extend([self.word2idx[self.pad] for i in range(self.max_sentence_len - len(targets))])\n",
        "        # batch = (inputs, targets)\n",
        "        # return batch, len(sentence)\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def read_sentence(self, data):\n",
        "        sentence = [self.SOS]\n",
        "        for word in data:\n",
        "            sentence.append(word)\n",
        "            if word == self.EOS:\n",
        "                yield sentence\n",
        "                sentence = [self.SOS]\n",
        "\n",
        "    def remove_tags(self, data):\n",
        "        \"\"\"\n",
        "        Remove tree tags from Penn Treebank dataset\n",
        "        \"\"\"\n",
        "        data = data.split(\")\")\n",
        "        out = []\n",
        "        for e in data:\n",
        "            e = e.split(\" \")\n",
        "            if e[-1] != \"\":\n",
        "                out.append(e[-1])\n",
        "        return out\n",
        "\n",
        "    def largest_sentence(self):\n",
        "        max_len = 0\n",
        "        for sentence in self.read_sentence(self.base_data):\n",
        "            if len(sentence) > max_len:\n",
        "                max_len = len(sentence)\n",
        "        return max_len\n",
        "\n",
        "    def convert_to_string(self, char_idx):\n",
        "        return ' '.join(self.idx2word[idx] for idx in char_idx)\n",
        "\n",
        "    def convert_to_idx(self, chars):\n",
        "        return [self.word2idx[char] for char in chars]\n",
        "\n",
        "    def __len__(self):\n",
        "        # return len(self.sentences)\n",
        "        raise NotImplementedError\n",
        "\n",
        "\n",
        "class PennTreeData(BaseTreeData):\n",
        "    def __init__(self, data_path):\n",
        "        super().__init__()\n",
        "        self.data = self.remove_tags(open(data_path, \"r\").read())\n",
        "        self.sentences = [sentence for sentence in self.read_sentence(self.data)]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sentence = self.sentences[idx]\n",
        "        inputs =  [self.word2idx[w] if self.word_counter[w] > self.rare_threshold else self.word2idx[self.rare] for w in sentence]\n",
        "        targets = [self.word2idx[w] if self.word_counter[w] > self.rare_threshold else self.word2idx[self.rare] for w in sentence[1:]]\n",
        "        # add padding\n",
        "        inputs.extend([self.word2idx[self.pad] for i in range(self.max_sentence_len - len(inputs))])\n",
        "        targets.extend([self.word2idx[self.pad] for i in range(self.max_sentence_len - len(targets))])\n",
        "        batch = (inputs, targets)\n",
        "        return batch, len(sentence)\n",
        "        \n",
        "    def __len__(self):\n",
        "      return len(self.sentences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_c2i_ESDQ8B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class encoder(nn.Module):\n",
        "  \n",
        "  def __init__(self, vocabulary_size, emb_dim, hidden_dim, lstm_layers, latent_size, device = 'cuda:0', dropout = 0):\n",
        "    \n",
        "    super(encoder,self).__init__()\n",
        "    self.embedding = nn.Embedding(num_embeddings=vocabulary_size,embedding_dim=emb_dim)\n",
        "    self.lstm = nn.LSTM(input_size = emb_dim, hidden_size = hidden_dim, num_layers=lstm_layers, batch_first=False, bidirectional = True)\n",
        "    self.mean_encoding = nn.Linear(hidden_dim * 2, latent_size)\n",
        "    self.sd_encoding = nn.Linear(hidden_dim * 2, latent_size)\n",
        "    self.softplus = nn.Softplus()\n",
        "#     self.dropout = dropout                 #do later\n",
        "#     self.emb_dropout = nn.Dropout(p)\n",
        "    \n",
        "  def forward(self, x, hid = None):\n",
        "    \n",
        "    x = x.to(device)\n",
        "    x = self.embedding(x)\n",
        "    \n",
        "    _ , hidden = self.lstm(x, hid)\n",
        "    \n",
        "    h = torch.cat([hidden[0], hidden[1]], dim=-1)\n",
        "    \n",
        "#     hidden = torch.stack(hidden).view(hidden[0].size(0),hidden[0].size(1),-1)\n",
        "    \n",
        "    mean = self.mean_encoding(h)\n",
        "\n",
        "    sd = self.softplus(self.sd_encoding(h))\n",
        "    \n",
        "    logvar = None\n",
        "    \n",
        "    return mean, logvar, sd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3V99PoNIxWq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#USING THE BASELINE WITH SOME MODIFICATIONS AS DECODER\n",
        "\n",
        "class RNNLM(nn.Module):\n",
        "    def __init__(self, vocabulary_size, bidirectional, embedding_dim,\n",
        "                 lstm_num_hidden=512, lstm_num_layers=3, device='cuda:0'):\n",
        "        super(RNNLM, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(num_embeddings=vocabulary_size,\n",
        "                                      embedding_dim=embedding_dim)\n",
        "        \n",
        "        self.lstm = nn.LSTM(input_size=embedding_dim,\n",
        "                            hidden_size=lstm_num_hidden,\n",
        "                            num_layers=lstm_num_layers,\n",
        "                            batch_first=False, bidirectional = bidirectional)\n",
        "        \n",
        "        \n",
        "        self.linear = nn.Linear(lstm_num_hidden*2, vocabulary_size)\n",
        "        \n",
        "    def forward(self, x, hidden = None, flag = True):\n",
        "        \n",
        "        x = self.embedding(x)\n",
        "        all_hidden, hidden = self.lstm(x, (hidden, hidden))\n",
        "        out = self.linear(all_hidden)\n",
        "\n",
        "        return out, hidden\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMaqHHnZI3Qd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class senvae(nn.Module):\n",
        "  \n",
        "  def __init__(self, emb_dim, padding_index, vocab_size, hidden_dim, lstm_layers, latent_size, epoch = 1, device = 'cuda:0' ):\n",
        "    \n",
        "    super(senvae,self).__init__()\n",
        "    \n",
        "    self.encoder = encoder(vocab_size, emb_dim, hidden_dim , lstm_layers, latent_size, device = 'cuda:0', dropout = 0)\n",
        "    self.latent_dim = latent_size\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.pad_idx = padding_index\n",
        "    self.emb_dim = emb_dim\n",
        "    self.vocab_size = vocab_size\n",
        "    self.lstm_layers = lstm_layers\n",
        "    self.epsilon = 1e-7\n",
        "    self.tanh = nn.Tanh()\n",
        "    self.latenttohidden = nn.Linear(latent_size, hidden_dim)\n",
        "    self.criterion = nn.CrossEntropyLoss(ignore_index = padding_index)\n",
        "    self.nllcriterion = nn.CrossEntropyLoss(ignore_index = padding_index) #, reduction = 'None')\n",
        "    self.recons_loss = torch.zeros([2 * self.lstm_layers, 1])\n",
        "    self.decoder = RNNLM(vocab_size, bidirectional=True, embedding_dim=emb_dim,\n",
        "                 lstm_num_hidden=hidden_dim, lstm_num_layers=lstm_layers, device='cuda:0')  \n",
        "\n",
        "  def forward(self, x, targets, n = 10):\n",
        "       \n",
        "    mean, logvar, sd = self.encoder(x)\n",
        "    \n",
        "    kl_loss = (sd ** 2 + mean**2 - ((sd) ** 2 + self.epsilon).log() - 1).sum(1).sum(1) * 0.5\n",
        "    \n",
        "    #calculating loss for multisample ELBO\n",
        "    \n",
        "    r = torch.FloatTensor([0]).to(device)\n",
        "    \n",
        "    for i in range(n):\n",
        "    \n",
        "      z = torch.randn([x.size(1), self.latent_dim]).to(device)\n",
        "      \n",
        "      z = z * sd + mean\n",
        "\n",
        "      h = self.tanh(self.latenttohidden(z))\n",
        "\n",
        "      output, _ = self.decoder(x, h)\n",
        "      output = output.view(x.size()[0]* x.size()[1], -1)\n",
        "\n",
        "      reconstruction_loss = F.cross_entropy(output, targets, ignore_index=self.pad_idx, \n",
        "                                                reduction=\"none\")\n",
        "      \n",
        "      r += reconstruction_loss.sum(dim=0)\n",
        " \n",
        "    rl = torch.div(r,n)  \n",
        "    total_loss = kl_loss.mean()  + rl\n",
        "    \n",
        "    h0 = self.tanh(self.latenttohidden(mean))\n",
        "    out, _ = self.decoder(x, h0)\n",
        "    \n",
        "    nll = None\n",
        "    return out, total_loss, nll  \n",
        "  \n",
        "  def temperature_sample(self, h, temperature):\n",
        "    h = h.squeeze()\n",
        "    distribution = torch.softmax(h/temperature, dim=0)    \n",
        "    return torch.multinomial(distribution,1).item()\n",
        "  \n",
        "  def test(self,dataset, first_word, device, decoding = \"greedy\", flag = True, max_len = 20, temperature = 2.0):\n",
        "\n",
        "    \n",
        "    with torch.no_grad():\n",
        "      x = torch.tensor(first_word, dtype=torch.long, device=device).view(1,1)\n",
        "      sentence = [x.item()]\n",
        "      mean, _ ,  sd = self.encoder(x)\n",
        "      eps = distb.MultivariateNormal(torch.zeros(mean.size(2)).to(device = 'cuda:0'), torch.eye(mean.size(2)).to(device = 'cuda:0'))\n",
        "      z = mean + eps.sample() * sd  \n",
        "      if(flag):\n",
        "        h0 = self.tanh(self.latenttohidden(mean)) \n",
        "      else:\n",
        "        h0 = self.tanh(self.latenttohidden(z)) \n",
        "      \n",
        "      # use this z for predicting all the words until '.' is found\n",
        "      all_hidden, hidden = self.decoder(x , h0)\n",
        "      \n",
        "      if(decoding == \"greedy\"):\n",
        "        sampled_word = torch.argmax(all_hidden, dim=2).item()\n",
        "      else:\n",
        "        sampled_word = self.temperature_sample(all_hidden, temperature)\n",
        "      sentence.append(sampled_word)\n",
        "      x = torch.tensor(sampled_word, dtype=torch.long, device=device).view(1,1)\n",
        "      \n",
        "      while(sentence[-1] != dataset.EOS and len(sentence) < max_len):\n",
        "        all_hidden, hidden = self.decoder(x, h0)\n",
        "        if(decoding == \"greedy\"):\n",
        "          sampled_word = torch.argmax(all_hidden, dim=2).item()\n",
        "        else:\n",
        "          sampled_word = self.temperature_sample(all_hidden, temperature)\n",
        "        sentence.append(sampled_word)\n",
        "        x = torch.tensor(sampled_word, dtype=torch.long, device=device).view(1,1)\n",
        "\n",
        "    return(sentence)\n",
        "\n",
        "  def test_interpolate(self,dataset, first_word, mean, sd, decoding = \"greedy\", flag = True, max_len = 20, temperature = 2.0):\n",
        "\n",
        "    \n",
        "    with torch.no_grad():\n",
        "      x = torch.tensor(first_word, dtype=torch.long, device=device).view(1,1)\n",
        "      sentence = [x.item()]\n",
        "      eps = distb.MultivariateNormal(torch.zeros(mean.size(2)).to(device = 'cuda:0'), torch.eye(mean.size(2)).to(device = 'cuda:0'))\n",
        "      z = mean + eps.sample() * sd  \n",
        "      if(flag):\n",
        "        h0 = self.tanh(self.latenttohidden(mean)) \n",
        "      else:\n",
        "        h0 = self.tanh(self.latenttohidden(z)) \n",
        "      \n",
        "      # use this z for predicting all the words until '.' is found\n",
        "      all_hidden, hidden = self.decoder(x , h0)\n",
        "      \n",
        "      if(decoding == \"greedy\"):\n",
        "        sampled_word = torch.argmax(all_hidden, dim=2).item()\n",
        "      else:\n",
        "        sampled_word = self.temperature_sample(all_hidden, temperature)\n",
        "      sentence.append(sampled_word)\n",
        "      x = torch.tensor(sampled_word, dtype=torch.long, device=device).view(1,1)\n",
        "      \n",
        "      while(sentence[-1] != dataset.EOS and len(sentence) < max_len):\n",
        "        all_hidden, hidden = self.decoder(x, h0)\n",
        "        if(decoding == \"greedy\"):\n",
        "          sampled_word = torch.argmax(all_hidden, dim=2).item()\n",
        "        else:\n",
        "          sampled_word = self.temperature_sample(all_hidden, temperature)\n",
        "        sentence.append(sampled_word)\n",
        "        x = torch.tensor(sampled_word, dtype=torch.long, device=device).view(1,1)\n",
        "\n",
        "    return(sentence)\n",
        "\n",
        "  def perplexity(self, model, dataloader, n = 5):\n",
        "    \n",
        "    #calculate perlpexity for entire dataset\n",
        "    log_px = 0.\n",
        "    num_sen = 0\n",
        "    num_preds = 0\n",
        "    accuracies = []\n",
        "    with torch.no_grad():\n",
        "    \n",
        "      for step, (batch, sen_lens) in enumerate(dataloader):\n",
        "\n",
        "        batch_inputs, batch_targets = batch\n",
        "            \n",
        "        batch_inputs = torch.stack(batch_inputs).to(device)\n",
        "        batch_targets = torch.stack(batch_targets).to(device).view(-1)\n",
        "        \n",
        "        mean,logvar, sd = self.encoder(batch_inputs)\n",
        "        \n",
        "        likelihoods = torch.FloatTensor(n,2,100).to(device)\n",
        "        losses = []\n",
        "        for i in range(n):\n",
        "\n",
        "          z = torch.randn([batch_inputs.size(1), self.latent_dim]).to(device)\n",
        "          z = z * sd + mean\n",
        "          h = self.tanh(self.latenttohidden(z))\n",
        "      \n",
        "          output, _ = self.decoder(batch_inputs, h)\n",
        "          output = output.view(batch_inputs.size()[0]* batch_inputs.size()[1], -1)\n",
        "          accuracy = (output.argmax(1) == batch_targets).float().sum()/(batch_targets != 0).sum()\n",
        "          accuracies.append(accuracy.item())\n",
        "          \n",
        "          #p(x|z)\n",
        "          logprob = F.cross_entropy(output, batch_targets, reduction=\"sum\")\n",
        "\n",
        "          # Calculate p(z|prior) and p(z|encoding) \n",
        "          \n",
        "          #prior_pz\n",
        "          prior = Normal(torch.zeros((mean.shape[1], self.latent_dim), device = device),torch.ones((mean.shape[1], self.latent_dim), device = device))\n",
        "          #posterior_qz\n",
        "          encoded_distribution = Normal(mean, sd)\n",
        "          normalizer = (prior.log_prob(z).exp()/encoded_distribution.log_prob(z).exp()).prod(1).unsqueeze(1)\n",
        "          \n",
        "          a = prior.log_prob(z).sum(dim = 1)\n",
        "          b = encoded_distribution.log_prob(z).sum(dim = 1)\n",
        "          c = logprob + a - b\n",
        " \n",
        "          d = logprob*normalizer +(logprob == 0).float()\n",
        "\n",
        "          likelihoods[i] = c\n",
        "        \n",
        "\n",
        "        log_px_batch = torch.logsumexp(likelihoods, dim = 0) - torch.log(torch.Tensor([n]).to(device))\n",
        "        log_px += log_px_batch.sum(-1)\n",
        "  \n",
        "        num_sen += sen_lens.size(0)\n",
        "        num_preds += sen_lens.sum()\n",
        "    \n",
        "    perplexity = log_px / (num_preds * batch_inputs.size(1))\n",
        "    NLL = log_px / num_sen\n",
        "    \n",
        "    return perplexity.mean(), NLL.mean(), np.mean(accuracies)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VZTYSJMQNdq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ELBO(model, dataloader, n = 10):\n",
        "  \n",
        "#   model.eval()\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    \n",
        "    rec_loss = torch.FloatTensor([0]).to(device)\n",
        "    kld = torch.FloatTensor([0]).to(device)\n",
        "    num_sen = 0\n",
        "    for step, (batch, sen_lens) in enumerate(dataloader):\n",
        "      \n",
        "      batch_inputs, batch_targets = batch      \n",
        "      batch_inputs = torch.stack(batch_inputs).to(device)\n",
        "      batch_targets = torch.stack(batch_targets).to(device).view(-1)\n",
        "\n",
        "      mean, _ , sd = model.encoder(batch_inputs)\n",
        "      \n",
        "\n",
        "      kl_loss = (sd ** 2 + mean**2 - ((sd ** 2) + model.epsilon).log() - 1).sum(1).sum(1) * 0.5\n",
        "\n",
        "      \n",
        "      #calculating loss for multisample ELBO\n",
        "\n",
        "      r = torch.FloatTensor([0]).to(device)\n",
        "      for i in range(n):\n",
        "\n",
        "        z = torch.randn([batch_inputs.size(1), model.latent_dim]).to(device)\n",
        "\n",
        "        z = z * sd + mean\n",
        "\n",
        "        h = model.tanh(model.latenttohidden(z))\n",
        "\n",
        "        output, _ = model.decoder(batch_inputs, h)\n",
        "        output = output.view(batch_inputs.size()[0]* batch_inputs.size()[1], -1)\n",
        "\n",
        "        reconstruction_loss = F.cross_entropy(output, batch_targets, ignore_index= model.pad_idx, \n",
        "                                                  reduction=\"none\")\n",
        "\n",
        "        r += reconstruction_loss.sum(dim=0)\n",
        "\n",
        "      rec_loss += r\n",
        "#       rec_loss = torch.div(rec_loss, n)\n",
        "      kld += kl_loss.mean()\n",
        "      num_sen += batch_inputs.size(1) #batch size\n",
        "      \n",
        "    #Average values\n",
        "    rec_loss = torch.div(rec_loss,num_sen)\n",
        "    normalizer = num_sen * (step + 1)\n",
        "    kld1 = torch.div(kld, normalizer)\n",
        "    kld2 = torch.div(kld, num_sen)\n",
        "    elbo = rec_loss + kld1\n",
        "    \n",
        "  return elbo.item() , kld1.item()\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtTKKMH1x4hZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def interpolation(test_dataset, test_data_loader, idx1, idx2, model):\n",
        "  \n",
        "  with torch.no_grad():\n",
        "\n",
        "    for i,j in test_data_loader:\n",
        "      s1 = []\n",
        "      s2 = []\n",
        "      for k in range(16):\n",
        "        #inside a [batch])\n",
        "        for a in i[k]:\n",
        "          #inside one batch element\n",
        "          b = a[idx1]\n",
        "          c = a[idx2]\n",
        "          s1.append(b)\n",
        "          s2.append(c)\n",
        "        break\n",
        "      break\n",
        "    a = torch.zeros(140,1).to(device)\n",
        "    d = torch.zeros(140,1).to(device)\n",
        "    for i in range(140):\n",
        "      a[i] = s1[i]\n",
        "      d[i] = s2[i]\n",
        "\n",
        "    print(\"First original statement\")\n",
        "    for i in a:\n",
        "      print(test_dataset.idx2word[i.item()], end = \" \")\n",
        "    print(\"\\n2nd original statement\")\n",
        "    for i in d:\n",
        "      print(test_dataset.idx2word[i.item()], end = \" \")\n",
        "    print(\"\")\n",
        "    s1 = a\n",
        "    s1 = s1.long().to(device)\n",
        "    s2 = d\n",
        "    s2 = s2.long().to(device)\n",
        "\n",
        "    mean1, _, sd1 = model.encoder(s1)\n",
        "    mean2, _, sd2 = model.encoder(s2)\n",
        "\n",
        "    mean_diff = (mean2 - mean1)/(idx2-idx1 +1)\n",
        "    means = [mean1 + mean_diff*i for i in range(10)]\n",
        "\n",
        "    for i, mean in enumerate(means):\n",
        "      generated_sample =  model.test_interpolate(test_dataset, test_dataset.word2idx[test_dataset.SOS], mean, sd1, decoding = \"greedy\", flag = True)\n",
        "      print(\"Interpolated reconstruction: \",test_dataset.convert_to_string(generated_sample))\n",
        "\n",
        "def reconstruct(model, test_dataset, test_data_loader, idx):\n",
        "  \n",
        "  with torch.no_grad():\n",
        "\n",
        "    for i,j in test_data_loader:\n",
        "      s1 = []\n",
        "      for k in range(16):\n",
        "        #inside a [batch])\n",
        "        for a in i[k]:\n",
        "          #inside one batch element\n",
        "          b = a[idx]\n",
        "          s1.append(b)\n",
        "        break\n",
        "      break\n",
        "    a = torch.zeros(140,1).to(device)\n",
        "    for i in range(140):\n",
        "      a[i] = s1[i]\n",
        "\n",
        "    print(\"Original statement\")\n",
        "    for i in a:\n",
        "      print(test_dataset.idx2word[i.item()], end = \" \")\n",
        "    print(\"\")\n",
        "    s1 = a\n",
        "    s1 = s1.long().to(device)\n",
        "    mean, _, sd = model.encoder(s1)\n",
        "\n",
        "    #flag = true for mean\n",
        "    generated_sample = model.test_interpolate(test_dataset, test_dataset.word2idx[test_dataset.SOS],mean, sd, decoding = \"greedy\", flag = True)\n",
        "    print(\"SAMPLE (gmean)\", \":\", test_dataset.convert_to_string(generated_sample))\n",
        "    generated_sample = model.test_interpolate(test_dataset, test_dataset.word2idx[test_dataset.SOS],mean, sd, decoding = \"temp\", flag = True)\n",
        "    print(\"SAMPLE (tmean)\", \":\", test_dataset.convert_to_string(generated_sample))\n",
        "\n",
        "    #flag = false for z\n",
        "    for i in range(10):\n",
        "      generated_sample = model.test_interpolate(test_dataset, test_dataset.word2idx[test_dataset.SOS],mean, sd, decoding = \"greedy\", flag = False)\n",
        "      print(\"SAMPLE_g\", i+1, \":\", test_dataset.convert_to_string(generated_sample))\n",
        "      generated_sample = model.test_interpolate(test_dataset, test_dataset.word2idx[test_dataset.SOS],mean, sd, decoding = \"temp\", flag = False)\n",
        "      print(\"SAMPLE_t\", i+1, \":\", test_dataset.convert_to_string(generated_sample))\n",
        "    \n",
        "def reconstruct_val(model, test_dataset, test_data_loader, idx):\n",
        "  \n",
        "  with torch.no_grad():\n",
        "\n",
        "    for i,j in test_data_loader:\n",
        "      s1 = []\n",
        "      for k in range(16):\n",
        "        #inside a [batch])\n",
        "        for a in i[k]:\n",
        "          #inside one batch element\n",
        "          b = a[idx]\n",
        "          s1.append(b)\n",
        "        break\n",
        "      break\n",
        "    a = torch.zeros(140,1).to(device)\n",
        "    for i in range(140):\n",
        "      a[i] = s1[i]\n",
        "\n",
        "    print(\"Original statement\")\n",
        "    for i in a:\n",
        "      print(test_dataset.idx2word[i.item()], end = \" \")\n",
        "    print(\"\")\n",
        "    s1 = a\n",
        "    s1 = s1.long().to(device)\n",
        "    mean, _, sd = model.encoder(s1)\n",
        "\n",
        "    #flag = true for mean\n",
        "    generated_sample = model.test_interpolate(test_dataset, test_dataset.word2idx[test_dataset.SOS],mean, sd, decoding = \"greedy\", flag = True)\n",
        "    print(\"SAMPLE (gmean)\", \":\", test_dataset.convert_to_string(generated_sample))\n",
        "    generated_sample = model.test_interpolate(test_dataset, test_dataset.word2idx[test_dataset.SOS],mean, sd, decoding = \"temp\", flag = True)\n",
        "    print(\"SAMPLE (tmean)\", \":\", test_dataset.convert_to_string(generated_sample))\n",
        "\n",
        "    #flag = false for z\n",
        "    for i in range(1):\n",
        "      generated_sample = model.test_interpolate(test_dataset, test_dataset.word2idx[test_dataset.SOS],mean, sd, decoding = \"greedy\", flag = False)\n",
        "      print(\"SAMPLE (gz)\", \":\", test_dataset.convert_to_string(generated_sample))\n",
        "      generated_sample = model.test_interpolate(test_dataset, test_dataset.word2idx[test_dataset.SOS],mean, sd, decoding = \"temp\", flag = False)\n",
        "      print(\"SAMPLE (tz)\", \":\", test_dataset.convert_to_string(generated_sample))\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCM0ACbVtcpz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_TEXT_FILE = \"02-21.10way.clean\"\n",
        "EVAL_TEXT_FILE = \"22.auto.clean\"\n",
        "TEST_TEXT_FILE = \"23.auto.clean\"\n",
        "  \n",
        "def train():\n",
        "  \n",
        "    \n",
        "    batch_size = 32\n",
        "    embedding_dimension = 128\n",
        "    lstm_num_hidden_l = 128\n",
        "    lstm_num_layers_l = 1\n",
        "    learning_rate = 0.001\n",
        "    n_epochs = 10\n",
        "    sample_method = 'greedy'\n",
        "    latent_size = 100\n",
        "    \n",
        "    # Initialize the dataset and data loader (note the +1)\n",
        "    train_dataset = PennTreeData(TRAIN_TEXT_FILE)\n",
        "    train_data_loader = DataLoader(train_dataset, batch_size, num_workers=1)\n",
        "    eval_dataset = PennTreeData(EVAL_TEXT_FILE)\n",
        "    eval_data_loader = DataLoader(eval_dataset, batch_size, num_workers=1)\n",
        "    test_dataset = PennTreeData(TEST_TEXT_FILE)\n",
        "    test_data_loader = DataLoader(test_dataset, batch_size, num_workers=1)\n",
        "    \n",
        "    # Initialize the model that we are going to use\n",
        "    model = senvae (embedding_dimension, train_dataset.word2idx[train_dataset.pad],  \n",
        "                    train_dataset.vocab_size, lstm_num_hidden_l, lstm_num_layers_l,\n",
        "                    latent_size, device = 'cuda:0' )\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "    # Setup the loss and optimizer\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index = train_dataset.word2idx[train_dataset.pad])\n",
        "    optimizer = optim.RMSprop(model.parameters(), lr = learning_rate)\n",
        "    \n",
        "    train_elbo = []\n",
        "    train_accuracies = []\n",
        "    val_elbo = []\n",
        "    val_accuracies = []\n",
        "    val_kld = []\n",
        "    val_ppl = []\n",
        "    val_nll = []\n",
        "    for epoch in range(n_epochs):\n",
        "        print(\"In epoch\", epoch)\n",
        "        for step, (batch, sen_lens) in enumerate(train_data_loader):\n",
        "            \n",
        "            model.zero_grad()\n",
        "            batch_inputs, batch_targets = batch\n",
        "            \n",
        "            # Only for time measurement of step through network\n",
        "            t1 = time.time()\n",
        "            batch_inputs = torch.stack(batch_inputs).to(device)\n",
        "            batch_targets = torch.stack(batch_targets).to(device).view(-1)\n",
        "\n",
        "  \n",
        "            output, loss, nll = model(batch_inputs, batch_targets)\n",
        "\n",
        "            output = output.view(batch_inputs.size()[0] * batch_inputs.size()[1], -1)\n",
        "            tloss = criterion(output,batch_targets)\n",
        "            accuracy = (output.argmax(1) == batch_targets).float().sum()/(batch_targets != 0).sum()\n",
        "            elbo = -loss            \n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            # For plotting\n",
        "            train_accuracies.append(accuracy)\n",
        "            train_elbo.append(-loss.item())\n",
        "            \n",
        "            # Just for time measurement\n",
        "            t2 = time.time()\n",
        "            examples_per_second = batch_size/float(t2-t1)\n",
        "           \n",
        "            if step % 100 == 0 : #config.print_every == 0:\n",
        "                print(\"[{}] Epoch {} Train Step {:00f}, Batch Size = {}, Examples/Sec = {:.2f}, \"\n",
        "                    \"Accuracy = {:.3f}, Loss = {:.5f} \".format(\n",
        "                        datetime.now().strftime(\"%Y-%m-%d %H:%M\"), epoch, step,\n",
        "                        batch_size, examples_per_second,\n",
        "                        accuracy, loss.item()))\n",
        "           \n",
        "          \n",
        "                print(\"Epoch\", epoch, \" completed\")\n",
        "                model.eval()\n",
        "                ppl, nll, acc = model.perplexity(model, eval_data_loader, n =10)\n",
        "                elbo, kld = ELBO(model, eval_data_loader)\n",
        "                val_accuracies.append(acc)\n",
        "                val_elbo.append(-elbo)\n",
        "                val_kld.append(kld)\n",
        "                val_ppl.append(ppl)\n",
        "                val_nll.append(nll)\n",
        "                print(\"Validation metrics: Batch Size = {}, Accuracy = {}, KL-D = {}, ELBO = {},\" \n",
        "                      \"Perplexity = {}, NLL = {} \".format(\n",
        "                          batch_size, acc, kld, elbo, ppl.item(), nll.item()))\n",
        "                generated_sample = reconstruct_val(model, eval_dataset, eval_data_loader, 1)\n",
        "#                 model.train()\n",
        "                break\n",
        "        break\n",
        "\n",
        "    print('Done training! Evaluating test set now')\n",
        "    model.eval()\n",
        "    ppl, nll, acc = model.perplexity(model, test_data_loader, n =10)\n",
        "    elbo, kld = ELBO(model, test_data_loader)\n",
        "    print(\"Test metrics: Batch Size = {}, Accuracy = {}, KL-D = {}, ELBO = {},\" \n",
        "          \"Perplexity = {}, NLL = {} \".format(\n",
        "              batch_size, acc, kld, elbo, ppl.item(), nll.item()))\n",
        "    print(\"**************RECONSTRUCTION CAPABILITY***************************\")\n",
        "    reconstruct(model, test_dataset, test_data_loader, 1)\n",
        "    print(\"****************INTERPOLATION CAPABILITY**************************\")\n",
        "    interpolation(test_dataset, test_data_loader, 0, 9, model)\n",
        "      \n",
        "    plt.plot(train_elbo, label = \"Train Loss\")\n",
        "    plt.legend()\n",
        "    plt.savefig(\"train_elbo.png\")\n",
        "    plt.close()\n",
        "    \n",
        "    plt.plot(train_accuracies, label = \"Train accuracy\")\n",
        "    plt.legend()\n",
        "    plt.savefig(\"train_acc.png\")\n",
        "    plt.close()\n",
        "    \n",
        "    plt.plot(val_elbo, label = \"Validation Loss\")\n",
        "    plt.legend()\n",
        "    plt.savefig(\"val_elbo.png\")\n",
        "    plt.close()\n",
        "    \n",
        "    plt.plot(val_accuracies, label = \"Val accuracy\")\n",
        "    plt.legend()\n",
        "    plt.savefig(\"val_acc.png\")\n",
        "    plt.close()\n",
        "    \n",
        "    plt.plot(val_kld, label = \"val kld\")\n",
        "    plt.legend()\n",
        "    plt.savefig(\"val_kld.png\")\n",
        "    plt.close()\n",
        "    \n",
        "    return model, train_elbo, train_accuracies, val_elbo, val_accuracies, val_kld , val_ppl, val_nll\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqJ8csMcGEqo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model, train_elbo, train_accuracies, val_elbo, val_accuracies, val_kld, val_ppl, val_nll  = train()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8rp6qJnjJPK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# np.save(\"train_elbo\", train_elbo)\n",
        "# np.save(\"train_acc\", train_accuracies)\n",
        "# np.save(\"val_elbo\", val_elbo)\n",
        "# np.save(\"val_accuracies\", val_accuracies)\n",
        "# np.save(\"val_kld\", val_kld)\n",
        "# np.save(\"val_ppl\", val_ppl)\n",
        "# np.save(\"val_nll\", val_nll)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXQFhwAMiapT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), \"svae.pt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uY7VchWwh8iv",
        "colab_type": "code",
        "outputId": "f882254a-8a61-4ef3-9895-ced5d53d5959",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-4Wq_vxycjQ",
        "colab_type": "code",
        "outputId": "27ee3043-d5c7-48e4-ad2d-dccd0c839c1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from shutil import copyfile\n",
        "\n",
        "copyfile('svae.pt', '/content/gdrive/My Drive/' + 'svae.pt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/My Drive/svae.pt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnMJO1N9FsH8",
        "colab_type": "code",
        "outputId": "fdbbb8e8-304f-4c4c-a127-50181690978a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "# import numpy as np\n",
        "# from matplotlib import pyplot as plt\n",
        "\n",
        "# a = np.load(\"train_elbo.npy\")\n",
        "# b = np.load(\"val_elbo.npy\")\n",
        "# c = np.load(\"val_accuracies.npy\")\n",
        "# b = b * -1\n",
        "# # plt.plot(a)\n",
        "# # plt.plot(b)\n",
        "# # plt.plot(c)\n",
        "\n",
        "\n",
        "\n",
        "# fig, ax1 = plt.subplots()\n",
        "# t = np.arange(0,10)\n",
        "# color = 'tab:red'\n",
        "# ax1.set_xlabel('epoch (s)')\n",
        "# ax1.set_ylabel('Loss', color=color)\n",
        "# ax1.plot(t,b, color=color)\n",
        "# ax1.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "# ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "\n",
        "# color = 'tab:blue'\n",
        "# ax2.set_ylabel('Accuracy', color=color)  # we already handled the x-label with ax1\n",
        "# ax2.plot(t, c, color=color)\n",
        "# ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "# fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nklygzMysklygzMysklygzMyskr4DvYMkviJDh9IAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jd2sfJeJGGfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}